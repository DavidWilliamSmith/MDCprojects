{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5412f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71121b",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "The first part of this notebook uses a toy dataset to illustrate __how splits are made and evaluated__ when constructing a classification tree.\n",
    "\n",
    "The example ilustrates splits done on a quantitative predictor (Income)\n",
    "\n",
    "The example evaluates the splits based on the error rate. Notice that the CART algorithm implemented in scikit learn does not use the error rate to make splits. It uses either the Gini index or Entropy (whichever the user chooses)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6a6e7",
   "metadata": {},
   "source": [
    "__Creating the toy dataset__\n",
    "\n",
    "There are three predictors. The outcome is Credit_Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc87bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df_classif=pd.DataFrame({'Savings':['Med','Low','High','Med','Low','High','Low','Med'], 'Assets':['High','Low','Med','Med','Med','High','Low','Med'], 'Income':[75,50,25,50,100,25,25,75], 'Credit_Risk':['Good','Bad','Bad','Good','Good','Good','Bad','Good']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c482a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate at the parent node is the proportion of the least frequent class (which is bad)\n",
    "\n",
    "3/ 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d22682",
   "metadata": {},
   "source": [
    "#### Exploring how splits are made when constructing a CT\n",
    "#### Exploring splits on Income\n",
    "\n",
    "The first thing to do bf creating the splits for a quantitative predictor is to __obtain the cutoff points__\n",
    "\n",
    "To obtain the possible cutoff points, we first store all Income values (excluding duplicates) in an array __x__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.sort(toy_df_classif['Income'].unique())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutpoints=[]\n",
    "for i in np.arange(len(x)-1):  # I need i to reach only to the second to last index (not the last one)\n",
    "                               # np.arange(len(x)-1) generates the numbers 0,1,2\n",
    "    cutpoints.append((x[i]+x[i+1])/2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e979c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39829d7b",
   "metadata": {},
   "source": [
    "The algorithm would do the split of Income based on these three cutpoints and would decide the best split (i.e., the split \n",
    "leading to the purest child nodes). \n",
    "\n",
    "The next code cells will show in details (step by step) how to obtain and evaluate ONLY the split done at 37.5.\n",
    "\n",
    "Later on, you will see a loop where all three cutoff points are evaluated.\n",
    "\n",
    "__Reminder__: The algorithm would also do all the possible splits for the other two predictors, Savings and Assets, and would actually choose the best split obtained across all three predictors and across all cutoffs tested for each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT NODE FOR CUTPOINT 37.5\n",
    "\n",
    "toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]\n",
    "\n",
    "# Alternative way: toy_df_classif[toy_df_classif['Income'] < 37.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851687bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIGHT NODE FOR CUTPOINT 37.5\n",
    "\n",
    "toy_df_classif.loc[toy_df_classif['Income']>= 37.5, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17328b91",
   "metadata": {},
   "source": [
    "__What's the prediction of Y for the left node? (show students Slide 4)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab9e03",
   "metadata": {},
   "source": [
    "Answer: The prediction is Bad because it is the most common class in this node. The next two code cells show you how to get this label programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]['Credit_Risk'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]['Credit_Risk'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e58a7",
   "metadata": {},
   "source": [
    "__What's the error rate at the left node?__\n",
    "\n",
    "Error rate for a given node = 1 - proportion of obs that belong to the predominant class\n",
    "\n",
    "Error rate for left node = 1- 2/3 (prop of obs that belong to Bad) = 1/3\n",
    "\n",
    "Altenative to compute the error rate at a node: Direct computation based on proportion of obs that belong to the least frequent class\n",
    "\n",
    "Error rate for left node = 1/3 (proportion for the least frequent class in this node, which is Good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06a7e9",
   "metadata": {},
   "source": [
    "__What's the prediction of Y for the right node?__\n",
    "\n",
    "Using the formula:\n",
    "Error rate for a given node = 1 - proportion of obs that belong to the predominant class\n",
    "\n",
    "Error rate for right node = 1- 4/5 (prop of obs that belong to Good)= 0.2\n",
    "\n",
    "Alternative computation: Direct computation based on proportion of obs that belong to the least frequent class\n",
    "\n",
    "Error rate for right node = 1/5= 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163b3f6",
   "metadata": {},
   "source": [
    "The next three code cells show you how to get the error rate for the left node using code (based on the direct computation = the proportion for the least frequent class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c847e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the minimum = the proportion for the least frequent class on the left node\n",
    "\n",
    "min(toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]['Credit_Risk'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the size of the left node\n",
    "\n",
    "toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f976e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the error rate by dividing these two quantities:\n",
    "\n",
    "min(toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]['Credit_Risk'].value_counts()) / toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14f46",
   "metadata": {},
   "source": [
    "Compute the error rate for the right node (based on the direct computation = the proportion for the least frequent class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9191e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(toy_df_classif.loc[toy_df_classif['Income'] >= 37.5, ]['Credit_Risk'].value_counts()) / toy_df_classif.loc[toy_df_classif['Income'] >= 37.5, ].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fc5b3",
   "metadata": {},
   "source": [
    "__What's the error associated with making a split at 37.5 based on Income?__\n",
    "\n",
    "Combine the error rate from both the left and right node!\n",
    "\n",
    "How can we combine these errors? We need to obtain the weighted average of the errors for the left and right nodes\n",
    "\n",
    "__Error for split at 37.5= weight for left node * error rate for left node + weight for right node * error rate for right node__\n",
    "\n",
    "weight for left node= obs that reached the left node/ obs before the split\n",
    "\n",
    "weight for right node= obs that reached the right node/ obs before the split\n",
    "\n",
    "Note: Notice that the unweighted average (which we do not need to compute), we will be obtained:\n",
    "\n",
    "Unweighted average = (error rate for left node + error rate for right node)/ 2 = 0.5 * error rate for left node + 0.5 * error rate for right node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_node_size= toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ].shape[0]\n",
    "left_node_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03566fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "right_node_size= toy_df_classif.loc[toy_df_classif['Income'] >= 37.5, ].shape[0]\n",
    "right_node_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce101a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error at left node\n",
    "\n",
    "error_left= min(toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ]['Credit_Risk'].value_counts()) / toy_df_classif.loc[toy_df_classif['Income'] < 37.5, ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6908de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error at right node\n",
    "\n",
    "error_right= min(toy_df_classif.loc[toy_df_classif['Income'] >= 37.5, ]['Credit_Risk'].value_counts()) / toy_df_classif.loc[toy_df_classif['Income'] >= 37.5, ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted error for the split\n",
    "\n",
    "error_left * (left_node_size/(left_node_size+right_node_size)) + error_right * (right_node_size/(left_node_size+right_node_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c3c80",
   "metadata": {},
   "source": [
    "The previous five code cells included the steps to compute the weighted error rate for the split at 37.5 on Income.\n",
    "\n",
    "The next loop summarizes the computation of the weighted error for the three splits on Income, that is the splits at 37.5, 62.5, and 87.5.\n",
    "\n",
    "We can get what's the best of all the splits for Income based on the output of this loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_splits =[]\n",
    "for i in cutpoints:\n",
    "    left_node_size= toy_df_classif.loc[toy_df_classif['Income'] < i, ].shape[0]\n",
    "    right_node_size= toy_df_classif.loc[toy_df_classif['Income'] >= i, ].shape[0]\n",
    "    error_left=min(toy_df_classif['Credit_Risk'][toy_df_classif['Income']<i].value_counts())/left_node_size\n",
    "    error_right=min(toy_df_classif['Credit_Risk'][toy_df_classif['Income']>=i].value_counts())/right_node_size\n",
    "    error_rate_splits.append(error_left*(left_node_size/(left_node_size+right_node_size)) + error_right*(right_node_size/(left_node_size+right_node_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e92de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=pd.DataFrame (data= error_rate_splits, index= cutpoints, columns=['Weighted Error for Split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0594d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.index.name = ('Cutout point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7bfd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ed714",
   "metadata": {},
   "source": [
    "The best split and only meaningful split is the one at 37.5 because it leads to the lowest error rate (and the only error rate lower than the one for the parent node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910f742",
   "metadata": {},
   "source": [
    "### BACK TO THE SLIDES !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f70e4e",
   "metadata": {},
   "source": [
    "### Example comparing error rate, Gini, and Entropy.\n",
    "\n",
    "The following example will show that the Gini index and Entropy are more sensitive to changes in the node probabilities than the error rate.\n",
    "\n",
    "- Y has two classes (0 and 1)\n",
    "- The node under consideration contains 800 obs, 400 from each class\n",
    "- Split 1 leads to a left node with 300 zeros and 100 ones AND a right node with  100 zeros and 300 ones.\n",
    "- Split 2 leads to a left node with 200 zeros and 400 ones AND a right node with  200 zeros and 0 ones.\n",
    "- Compute the error rate, Gini, and Entropy for both splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a26180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate split 1\n",
    "\n",
    "# Reminder: Error rate for a split=  Average weighted error \n",
    "\n",
    "# Average weighted error= Weight for left node * error rate for left node + weight for right node * error rate for right node\n",
    "\n",
    "(400/800)* (100/400) + (400/800)* (100/400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2316bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error rate split 2\n",
    "\n",
    "(600/800)* (200/600) + (200/800)* (0/200) # the right node for split 2 is completely pure!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9ecf4",
   "metadata": {},
   "source": [
    "According to the error rate, splits 1 and 2 are equally good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini split 1\n",
    "\n",
    "# Gini index for a split= Weighted Gini for the split\n",
    "\n",
    "# Weight for left node * Gini for left node + weight for right node * Gini for right nod\n",
    "\n",
    "# G= 2 p1 (1-p1)\n",
    "\n",
    "\n",
    "(400/800)* (2*(100/400)*(300/400)) + (400/800)* (2*(300/400)*(100/400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef561a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini split 2\n",
    "\n",
    "(600/800)* (2*(400/600)*(200/600)) + (200/800)* (2*(0/200)*(200/200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddea4a",
   "metadata": {},
   "source": [
    "According to Gini, split 2 is better. Gini heavily weighs the fact that split 2 gives us a perfectly pure node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy split 1\n",
    "\n",
    "# Entropy for a split= Weighted Entropy for the split\n",
    "\n",
    "# Weight for left node * Entropy for left node + weight for right node * Entropy for right node\n",
    "\n",
    "# D= - (1-p1) * log (1 -p1) - p1 * log(p1)\n",
    "\n",
    "# Reminder: p1 for the left node in split 1 is 100/400\n",
    "# Reminder: p1 for the right node in split 1 is 300/400\n",
    "\n",
    "(400/800)* (-(300/400)*np.log(300/400)- (100/400)*np.log(100/400)) + \\\n",
    "(400/800)* (-(100/400)*np.log(100/400) -(300/400)*np.log(300/400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy split 2\n",
    "\n",
    "# D= - (1-p1) * log (1 -p1) - p1 * log(p1)\n",
    "\n",
    "# Reminder: p1 for the left node in split 2 is 400/600\n",
    "\n",
    "(600/800)* (-(200/600)*np.log(200/600)-(400/600)*np.log(400/600)) + (200/800)* 0\n",
    "\n",
    "# log (0) is undefined. However, when you are in a situation where you are computing the entropy \n",
    "# and you get log (0), you can make log(0) equals to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb05c4d",
   "metadata": {},
   "source": [
    "According to the Entropy, split 2 is better. Similarly to Gini, Entropy heavily weighs the fact that split 2 gives us a perfectly pure node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bce7a",
   "metadata": {},
   "source": [
    "### BACK TO THE LAST SLIDES !\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cd8f5",
   "metadata": {},
   "source": [
    "## Example 1: Obtaining a classification tree for the caravan insurance data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74072862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method needed to apply the GridSearch pre-prunning strategy!\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ef418",
   "metadata": {},
   "outputs": [],
   "source": [
    "Caravan_df= pd.read_csv('C:\\\\Users\\\\jheredi2\\\\Documents\\\\PythonDataAnalytics\\\\1-Datasets\\\\Caravan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9985a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Caravan_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df0c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(Caravan_df['Purchase'].value_counts()/Caravan_df['Purchase'].size)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I chose to exclude the first predictor from the Caravan dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split (Caravan_df.iloc[:,1:-1], Caravan_df['Purchase'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb4d13",
   "metadata": {},
   "source": [
    "## Pre-pruning via Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid1 = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': np.arange(1,11),\n",
    "    'min_samples_split':[0.1, 0.15, 0.2],\n",
    "    'min_samples_leaf':[0.05, 0.1, 0.15], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch1 = GridSearchCV(DecisionTreeClassifier(), hyperparam_grid1, cv=5,scoring='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11315812",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04442ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial parameters are: ', gridSearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4591f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid2 = {\n",
    "    'criterion': ['gini'],\n",
    "    'splitter': ['best'],\n",
    "    'max_depth': np.arange(1,5),\n",
    "    'min_samples_split':[0.08, 0.1, 0.12],\n",
    "    'min_samples_leaf':[0.02, 0.05, 0.08], \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch2 = GridSearchCV(DecisionTreeClassifier(), hyperparam_grid2, cv=5,scoring='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02dd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved parameters are: ', gridSearch2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_preprunned= DecisionTreeClassifier(criterion='gini' , splitter= 'best', max_depth= 1, min_samples_split=0.08, min_samples_leaf=0.02, min_impurity_decrease=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_preprunned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))   \n",
    "tree.plot_tree(tree_caravan_preprunned,filled=True, rounded= True, feature_names=X_train.columns, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "caravan_predicted_test= tree_caravan_preprunned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc31bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, caravan_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8910415",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report (y_test, caravan_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3dd80",
   "metadata": {},
   "source": [
    "## Post-pruning via CCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b45146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a903e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are growing the long/unprunned tree using Gini (which is the default criterion)\n",
    "\n",
    "tree_caravan_unprunned= DecisionTreeClassifier(criterion='gini', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9767278",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= tree_caravan_unprunned.cost_complexity_pruning_path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas= path['ccp_alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores=[]\n",
    "for i in alphas:\n",
    "    treeloop= DecisionTreeClassifier(ccp_alpha=i, random_state=1)\n",
    "    treeloop.fit(X_train, y_train)\n",
    "    y_test_predicted=treeloop.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_test_predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmax=accuracy_scores.index(max(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_postprunned= DecisionTreeClassifier(ccp_alpha= alphas[indexmax], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17498708",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_postprunned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d78e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))   \n",
    "tree.plot_tree(tree_caravan_postprunned,filled=True, rounded= True, feature_names=X_train.columns, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "caravan_postprunned_predicted_test= tree_caravan_postprunned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, caravan_postprunned_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377a3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (classification_report (y_test, caravan_postprunned_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef5888",
   "metadata": {},
   "source": [
    "## Example 2: Obtaining a classification tree for the Default data set\n",
    "\n",
    "## ONLY apply post-pruning via CCP\n",
    "\n",
    "You will have 10 minutes to work on this task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
