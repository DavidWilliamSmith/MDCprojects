{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244cd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8a62a",
   "metadata": {},
   "source": [
    "## Intro to Pandas\n",
    "\n",
    "Pandas objects can be thought of as enhanced versions of NumPy arrays in which the rows and columns can be identified with labels rather than simple integer indices.\n",
    "\n",
    "The row labels for Pandas objects are called indexes.\n",
    "\n",
    "The column labels for Pandas objects are called column names.\n",
    "\n",
    "The two most widely used __Pandas data structures__ are __Series__ and __DataFrame__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2e65c",
   "metadata": {},
   "source": [
    "### Series in Pandas\n",
    "\n",
    "A Pandas Series is a one-dimensional array of indexed data. It is a column of data where each value has an index. This index could be an integer (0,1,2,...) or a texttual label (e.g., person 1, person 2,... ).\n",
    "\n",
    "Here is the general syntax to create a series: *pd.Series(data, index=index)*, where data can be:\n",
    "\n",
    "- An array\n",
    "- A list\n",
    "- A dictionary\n",
    "\n",
    "The default index is an integer sequence starting at zero. We can always define our indexes if we do not want the default integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex: Creating a series from a list:\n",
    "\n",
    "Seriesx= pd.Series([0.25, 0.5, 0.75,1])\n",
    "\n",
    "Seriesx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fc19f",
   "metadata": {},
   "source": [
    "When creatring Seriesx, we did not define an index; thefore, a defaul index was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309cc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can access both a Series' values and its indexes\n",
    "# The values of a Series are a NumPy array\n",
    "\n",
    "Seriesx.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063acc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Seriesx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesx.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a42904",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Seriesx.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f95ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can indexed and sliced Series as we do with arrays\n",
    "\n",
    "Seriesx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af57b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Seriesx[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0c848",
   "metadata": {},
   "source": [
    "If we do not want to use the default index for the Series that we create, we can define our own index. See next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesx1= pd.Series([0.25, 0.5, 0.75,1], index=['a','b','c','d'])\n",
    "\n",
    "Seriesx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deed3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesx1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing a Series based on a non-numeric explicitely defined index\n",
    "\n",
    "Seriesx1['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51666826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also choose to index a Series using the implicit integer index\n",
    "\n",
    "Seriesx1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e305fd6",
   "metadata": {},
   "source": [
    "#### What's the difference btw a NumPy array and Pandas Series?\n",
    "\n",
    "The essential difference is the presence of the index: while a Numpy Array has an implicitly defined integer index used to access the values, in a Pandas Series, we can explicitly define an index if we want to.\n",
    "\n",
    "Defining our own indexes is an advantage. For example, the index need not be an integer, but can consist of values of any desired type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c010b8",
   "metadata": {},
   "source": [
    "### Data frames in Pandas\n",
    "\n",
    "If a Series is the equivalent of a one-dimensional NumPy array with flexible indixes, a data frame is the equivalent of a two-dimensional NumPy array. What's the difference between a two dimensional NumPy array and a Pandas data frame?\n",
    "\n",
    "A two dimensional NumPy array only has implicit integer indexes for both the rows and cols\n",
    "\n",
    "A Pandas data frame has flexible row indices and flexible column names (flexible= you can change the implicit integer indexes and define your own)\n",
    "\n",
    "Thus a data frame can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns can have an explicitely defined index for accessing the data.\n",
    "\n",
    "\n",
    "### Constructing DataFrame objects\n",
    "\n",
    "A Pandas data frame can be constructed in a variety of ways.\n",
    "\n",
    "The following webpages have nice summaries on the different ways of creating dataframes:\n",
    "\n",
    "https://towardsdatascience.com/15-ways-to-create-a-pandas-dataframe-754ecc082c17\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0522daf",
   "metadata": {},
   "source": [
    "#### Creating a data frame from a two-dimensional NumPy array\n",
    "\n",
    "Given a two-dimensional array of data, we can create a data frame with any specified column and index names. \n",
    "If the index defition is omitted, an integer index will be used for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a two dimensional array that we will then use to create a data frame\n",
    "\n",
    "a= np.full((3,2),10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data= a, columns=['x1','x2'], index=['a','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f376afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF from a two-dimensional array ommiting the index definition\n",
    "\n",
    "pd.DataFrame(data= a, columns=['x1','x2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d665d",
   "metadata": {},
   "source": [
    "#### Creating a data frame by passing the following arguments to pd.DataFrame(): a list with the observations (i.e., rows), and the column and index names\n",
    "\n",
    "__Note__: This is not a common way of creating a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3ab10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(data=[['Accounting',55000],['Engineering',65000],['Engineering',85000],['Human Resources',78000]], columns=['Department','Salary'],index=['Bob','Jake','Lisa','Sue'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa74f38",
   "metadata": {},
   "source": [
    "#### Creating a data frame by passing a data dictionary to pd.DataFrame()\n",
    "\n",
    "In this case, each key is a column name and the value for each key is a list with the data for the column.\n",
    "\n",
    "\n",
    "__Reminder__: This is the structure of a dictionary:\n",
    "\n",
    "dictionary_x= {'key1': values for key1, 'key2': values for key2, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame (data={'Department':['Accounting','Engineering','Engineering','Human Resources'],'Salary':[55000, 65000, 85000, 78000]}, index=['Bob','Jake','Lisa','Sue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8139e3",
   "metadata": {},
   "source": [
    "### Indexing and Slicing (= Subsetting) data frames and series\n",
    "\n",
    "Indexing Pandas Dataframes and Series is similar to indexing NumPy arrays. However, there are a few differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of indexing a Pandas series. Use the Seriesy as example\n",
    "\n",
    "Seriesy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last element\n",
    "\n",
    "Seriesy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last element usnig its explicit index\n",
    "\n",
    "Seriesy['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing by explicit index\n",
    "\n",
    "Seriesy['b':'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing by implicit integer index\n",
    "\n",
    "# b is index 1, c is index 2, and d is index 3. \n",
    "\n",
    "Seriesy[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e1079",
   "metadata": {},
   "source": [
    "#### Indexers: loc and iloc\n",
    "\n",
    "These are special indexer attributes that help us avoid the confusion that can arise given that we \n",
    "can index Series and Dataframes using an explicit index (if defined) or the implicit integer indexes.\n",
    "\n",
    "The i in __iloc__ means \"integer\", which means that iloc indexing uses the implicit integer indexes.\n",
    "\n",
    "The __loc__ should be used when the Series (or data frame) has explicitely defined indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c208756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loc attribute allows indexing and slicing that always refer to the explicit index:\n",
    "\n",
    "Seriesy.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesy.loc[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20c774",
   "metadata": {},
   "source": [
    "The previous statement returns an error because the indexes of Seriesy have been explictily defined using letters. \n",
    "\n",
    "Therefore, we cannot use the implicit integer index with loc if another index has been defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76fcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iloc attribute allows indexing and slicing that always references the implicit integer index:\n",
    "\n",
    "Seriesy.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesy.iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89647d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seriesy.loc['b':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de8ade",
   "metadata": {},
   "source": [
    "As we saw earlier, we can indexed and sliced Series and Dataframes without using loc and iloc. However, I think it is good practice to always index and slice Series and Dataframes by using either loc or iloc, so that we can be clear about what index we are using (the implicit or the explicit in case it has been defined)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ecfa5",
   "metadata": {},
   "source": [
    "### Indexing a Pandas DataFrame\n",
    "\n",
    "We can index a __Pandas Dataframe column__ using a dictionary-style approach (i.e., using the col or cols name(s) inside a bracket)  or using an attribute-style approach(i.e., df.col_name). Both method yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e58979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets's use df1 as a example\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to df1 \n",
    "\n",
    "df1['Age']=[25,28,36,45]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing using the column name, dictionary style\n",
    "\n",
    "df1['Department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1['Department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Department'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['Department','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1[['Department','Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing using the column name, attribute style\n",
    "\n",
    "df1.Department"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31089cba",
   "metadata": {},
   "source": [
    "__Comment__: Although the attribute-style indexing is easy to apply, keep in mind that it does not work for all cases! \n",
    "For example, if the column names are not strings, or if the column names conflict with methods of the DataFrame, the attribute-style access is not possible. For example, the DataFrame class has a pop() method. If a col name is \"pop\", dataframe.pop will point to the method rather than the \"pop\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b9ab2",
   "metadata": {},
   "source": [
    "If you pass numeric or Boolean indexes to slice a data frame WITHOUT specifying if they apply to rows or cols, \n",
    "they will be applied row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ff231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numeric indexes on a DF\n",
    "\n",
    "df1[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8608405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Boolean indexes on a DF\n",
    "\n",
    "df1[[True, True, False, True]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7d735",
   "metadata": {},
   "source": [
    "Avoid statements like these, use loc or ilco with data frames and series. See next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[1:3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How this work? df1.loc[1:3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[[True, True, False, True], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[[True, True, False, True], ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef9330",
   "metadata": {},
   "source": [
    "#### Examples of using iloc and loc with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a DF using iloc\n",
    "\n",
    "df1.iloc[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing a DF using loc\n",
    "\n",
    "df1.loc[['Bob','Jake','Lisa'],'Department':'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d2293",
   "metadata": {},
   "source": [
    "__IMPORTANT__: As this example showed, iloc uses Python's default indexing (where the upper lim isn't included),\n",
    "but loc uses explicit indexing where the upper lim is indeed included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOTHER EXAMPLE\n",
    "# Let's create a dataframe without defined indexes and see what happens:\n",
    "\n",
    "df2=pd.DataFrame(data= np.full((3,2),10), columns=['x1','x2'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[0:2, :'x2']\n",
    "\n",
    "# iloc is for implicit indexes, but 'x2' is explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000485cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[0:2, :'x2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20926a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.loc[0:2,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3d8618",
   "metadata": {},
   "source": [
    "We got an error with the previous statement because __loc__ uses explicitely defined indexes. df2 has defined col names (x1 and x2), so, when we use __loc__, we need to use those names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results of using df2.iloc[0:2,] and df2.loc[0:2,]\n",
    "\n",
    "df2.iloc[0:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[0:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48bc3ea",
   "metadata": {},
   "source": [
    "__Comment__: It might be confusing to use loc when the indexes are not defined like in the case of df2.\n",
    "When indexes are not defined, I think is better to SLICE a DF using iloc, which uses implicit integer indexes and standard Python conventions for indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def3527",
   "metadata": {},
   "source": [
    "__Comment__\n",
    "\n",
    "If an index has not been defined; that is, the implicit integer index is the index, we can use both iloc and loc with the implicit integer index. However, in such a case, we should stick with iloc (loc behaves oddly with implicit integer indexes)\n",
    "\n",
    "If an explicit index has been defined, we can use loc with this explicit index, but can still use iloc with the implicit integer index. However, in such a case, we should use loc and the explicit index (otherwise, what's the point of having an explicit index?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52c459",
   "metadata": {},
   "source": [
    "### Boolean arrays as indexes (i.e., Boolean masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex: Subsetting df1 using a Boolean index\n",
    "\n",
    "df1.loc[df1['Age']>30, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63de9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would work as well, but the previous statement using .loc is better (= clearer)\n",
    "\n",
    "df1.loc[df1['Age']>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f819d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex: Subsetting some columns of df1 using a Boolean index\n",
    "\n",
    "df1.loc[df1['Age']>30, ['Department', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd99ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex: More complex Boolean expression\n",
    "\n",
    "df1.loc[(df1['Age']>20) & (df1['Salary']<70000), ['Department', 'Salary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90773f6d",
   "metadata": {},
   "source": [
    "When writing a complex Boolean expression like the previous one, it is a good idea to save it in a variable and then use this varianle to index the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt=(df1['Age']>20) & (df1['Salary']<70000)\n",
    "\n",
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[filt, ['Department', 'Salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f801e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to index a single column using a Boolean mask?\n",
    "# Option 1: Use loc to slice the desired rows and the desired column\n",
    "\n",
    "df1.loc[df1['Age']>30, 'Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# Get the column that you desired, then, slice that colum using a Boolean mask\n",
    "\n",
    "df1['Salary'][df1['Age']>30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61f96e",
   "metadata": {},
   "source": [
    "From what I have seen, option 1 is more often used than option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3095cdc2",
   "metadata": {},
   "source": [
    "### NOTE: Do not go over the \"Handling Null Values in Pandas\" cells in class. Leave them for students to review independently. Why?\n",
    "\n",
    "a) You will not need the following ideas for any assignments\n",
    "\n",
    "b) It is unlikely that we need the following ideas for any of the code we will write in the two Machine Learning courses\n",
    "\n",
    "\n",
    "The ideas covered in the folling cells are useful, so, it will be good if you can review them independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1b278",
   "metadata": {},
   "source": [
    "### Handling Null Values in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use df2 as starting point\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add one more column, x3, to df2\n",
    "\n",
    "df2['x3']=np.full(3,10)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add more rows to df2\n",
    "\n",
    "df2=pd.concat([df2,df2], ignore_index= True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a57bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add three NaN values to df2\n",
    "# Add NaN to row 2 and the last row of x1 \n",
    "# Use np.nan\n",
    "\n",
    "df2.loc[[1,5],'x1']=np.nan\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de54b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another NaN in the first row of x3\n",
    "\n",
    "df2.loc[0,'x3']=np.nan\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832159c",
   "metadata": {},
   "source": [
    "Useful methods to handle missing values:isnull(), notnull(), and dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which rows in x1 have missing values\n",
    "\n",
    "df2['x1'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb35f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows in df2 where x1 is NULL\n",
    "\n",
    "df2.loc[df2['x1'].isnull(), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows in df2 where x1 is NULL. Alternative 2\n",
    "\n",
    "df2[df2['x1'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ffbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows in df2 where x1 is NOT NULL\n",
    "\n",
    "df2.loc[df2['x1'].notnull(), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f51754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All x1 values that aren't NULL\n",
    "\n",
    "df2.loc[df2['x1'].notnull(),'x1' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All x1 values that aren't NULL\n",
    "\n",
    "df2['x1'] [df2['x1'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To eliminate rows or cols with null values, we can use: dropna()\n",
    "# By defacult, dropna() drops rows with null values\n",
    "\n",
    "df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c75a2",
   "metadata": {},
   "source": [
    "Another useful function is fillna(). It can be used to fill out null values. Study independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb3a87",
   "metadata": {},
   "source": [
    "### Grouping in Pandas\n",
    "\n",
    "#### Grouping example: The developers dataset\n",
    "\n",
    "Download the developers csv file from Blackboard into your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev= pd.read_csv('C:\\\\Users\\\\jheredi2\\\\Documents\\\\PythonDataAnalytics\\\\1-Datasets\\\\survey_results_public.csv', index_col='Respondent')\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a023a",
   "metadata": {},
   "source": [
    "Before we cover grouping, let's see how to __sort the columns of a Pandas dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d61ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the Age column\n",
    "# First, remove NAs and zeros\n",
    "\n",
    "filter_Age= (df_dev['Age'].notnull()) & (df_dev['Age']!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8db50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dev.loc[filter_Age, 'Age'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f185e2dc",
   "metadata": {},
   "source": [
    "Obviously more cleaning is needed because some people said they were 1 year old. Other said they were 99 years old.\n",
    "\n",
    "We are going to skip this cleaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to sort in descending order\n",
    "\n",
    "df_dev.loc[filter_Age, 'Age'].sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use sort_values() to sort all the rows of the dataframe according to a column\n",
    "\n",
    "df_dev.loc[filter_Age, ].sort_values('Age', ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9c0fd",
   "metadata": {},
   "source": [
    "Use of the __groupby() method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.groupby('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2636fe",
   "metadata": {},
   "source": [
    "The groupby() method returns a __DataFrameGroupBy__ object\n",
    "\n",
    "A DataFrameGroupBy object is like an object that contains many dataframes, where each dataframe contains the data for each group (for each country in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get each of those dataframes independently by using get_group()\n",
    "\n",
    "df_dev.groupby('Country').get_group('United States')\n",
    "\n",
    "# This returns a DataFrame object.\n",
    "# Especifically, the dataframe for the rows where Country=='United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118018fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As practice, get the previous dataframe without using the groupby() method. \n",
    "# Instead, use an index to filter the dataframe\n",
    "\n",
    "filter_country= df_dev[\"Country\"] == \"United States\"\n",
    "\n",
    "df_dev.loc[filter_country, ]\n",
    "\n",
    "# Alternative code:  df_dev[filter_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of users for each social media app in each country\n",
    "\n",
    "df_dev.groupby('Country')['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the results to see it better ...\n",
    "\n",
    "df_dev.groupby('Country')['SocialMedia'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of object was returned in the previous statement?\n",
    "\n",
    "type(df_dev.groupby('Country')['SocialMedia'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the object mentioned in the previous cell\n",
    "\n",
    "df_dev.groupby('Country')['SocialMedia'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b40a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can index that Series for one specific group(= country):\n",
    "\n",
    "# Ex: Get the count of social media users per app for US participants\n",
    "\n",
    "\n",
    "df_dev.groupby('Country')['SocialMedia'].value_counts()['United States']\n",
    "\n",
    "# Sequence followed by the code: Get all the groups, get one column from all the groups, get the counts, \n",
    "# and then get one specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find another way of getting the results from the previous statement, still using the groupby() method:\n",
    "\n",
    "\n",
    "df_dev.groupby('Country').get_group('United States')['SocialMedia'].value_counts()\n",
    "\n",
    "\n",
    "# Sequence followed by the code: Get all the groups, get one specific group, get one column from that specific group, \n",
    "# and then get the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median salary for developers in different countries\n",
    "# The salary data is stored in the column named \"ConvertedComp\"\n",
    "\n",
    "df_dev.groupby('Country')['ConvertedComp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median salary for developers in India\n",
    "\n",
    "df_dev.groupby('Country')['ConvertedComp'].median()['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a34193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median salary for developers in India: Alternative 2\n",
    "\n",
    "df_dev.groupby('Country').get_group('India')['ConvertedComp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the median and mean salary for developers in different countries\n",
    "\n",
    "df_dev.groupby('Country')['ConvertedComp'].agg(['median','mean'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
