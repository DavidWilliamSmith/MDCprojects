{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed255c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df=pd.DataFrame(boston_data.data, columns= boston_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df['medv']= boston_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8363d9",
   "metadata": {},
   "source": [
    "### Post-pruning approach 1: selecting alpha via the validation set approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split (boston_df.iloc[:,:-1],boston_df['medv'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_boston_unprunned= DecisionTreeRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e056990",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= reg_tree_boston_unprunned.cost_complexity_pruning_path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a0c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alphas= path['ccp_alphas']\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026b4ea",
   "metadata": {},
   "source": [
    "Let's use each alpha to obtain a tree with the training data. Obtain the test MSE of the tree using the test data\n",
    "\n",
    "Therefore, each alpha will have a test MSE associated to it\n",
    "\n",
    "Our goal will be to choose the alpha leading to the lowest test MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores=[]\n",
    "for i in alphas:\n",
    "    treeloop= DecisionTreeRegressor(ccp_alpha=i,random_state=1)\n",
    "    treeloop.fit(X_train, y_train)\n",
    "    y_test_predicted=treeloop.predict(X_test)\n",
    "    mse_scores.append(mean_squared_error( y_test,y_test_predicted)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef4e0d",
   "metadata": {},
   "source": [
    "__PROGRAMMING TIP:__ Initially, I had written the previous for loop like this:\n",
    "\n",
    "mse_scores=[]\n",
    "\n",
    "for i in alphas:\n",
    "\n",
    "    tree= DecisionTreeRegressor(ccp_alpha=i,random_state=1)\n",
    "    \n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_predicted=tree.predict(X_test)\n",
    "    \n",
    "    mse_scores.append(mean_squared_error( y_test,y_test_predicted)) \n",
    "    \n",
    "\n",
    "Calling the object __tree__ was a huge mistake since it messes up with the tree class part of scikit learn. It prevented the tree from ploting. I was getting the following error when attempting to plot the tree:\n",
    "\n",
    "'DecisionTreeRegressor' object has no attribute 'plot_tree'\n",
    "\n",
    "NEVER CALL AN OBJECT WITH THE SAME NAME OF BUILT-IN CLASSES AND METHODS !!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32750bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the nice .index() method available for lists!\n",
    "\n",
    "indexmin=mse_scores.index(min(mse_scores))\n",
    "indexmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas[indexmin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370a1b9",
   "metadata": {},
   "source": [
    "Now, let's just obtain the tree with this alpha (the alpha that resulted in the lowest test MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_boston_prunned= DecisionTreeRegressor(ccp_alpha= alphas[indexmin], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e2a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_boston_prunned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24155053",
   "metadata": {},
   "source": [
    "As we saw in a previous code cell, the estimated test MSE for this tree was 14.0471... If you want to get it again, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624aab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error( y_test, reg_tree_boston_prunned.predict (X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa980161",
   "metadata": {},
   "source": [
    "This is very good (low) prediction error. It is much lower than the test MSE obtained with the best tree obtained from pre-pruning (previous notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d362d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tree\n",
    "plt.figure(figsize=(30,20))   \n",
    "tree.plot_tree(reg_tree_boston_prunned, filled=True, rounded= True, feature_names=X_train.columns, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f9bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To know what variables are in the tree\n",
    "\n",
    "boston_df.iloc[:,:-1].columns [reg_tree_boston_prunned.feature_importances_!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594ef06",
   "metadata": {},
   "source": [
    "### Interpreting the tree (Only if time permits. Otherwise, leave it for students to read at home independently)\n",
    "\n",
    "\n",
    "- As we already knew from previous examples, lower values of LSTAT are linked to higher values of medv. This can be seen in the color pattern shown by the leaves. Darker leaves (higher values of medv) are more prevalent on the branch to the left of the root node. This left branch is related to lower values of LSTAT (LSTAT <= 9.73)\n",
    "\n",
    "\n",
    "- When LSTAT is low, its influence on medv seems to depend on the values of other predictors. For large values of LSTAT, other predictors do not matter much! In other words, for neighborhoods where the % of houses with low SES (LSTAT) is above 9.73%, the median value of the houses does not depend MUCH on other factors because it is mostly determined by the value of LSTAT. The only exception is when LSTAT is really high; that is, above 16.09%, where a neighborhood with a value of NOX (Nitrogen oxides concentration in the air) less than or equal to 0.6, attenuates the impact of the high LSTAT on the house value.\n",
    "\n",
    "Note: I state that it \"attenuates\" it because for NOX <= 0.6, medv stops the trend to keep going down (medv at the leaf is 17.79 compared to 14.412 at the NOX node)\n",
    "\n",
    "\n",
    "#### Because the left branch of the tree starting at the root node has many nodes, I think that interpreting this branch is simplified if we write the rules that can be extracted from that branch. Let's write these rules:\n",
    "\n",
    "<br>\n",
    "\n",
    "Rule 1: __When LSTA <= 9.73% AND RM > 7.74 then: predicted medv= $ 44 318__\n",
    "\n",
    "<br>\n",
    "\n",
    "Rule 2: __When LSTA <= 9.73% AND RM <= 7.74 AND DIS <=1.485 then: predicted medv= $ 50 000__\n",
    "\n",
    "<br>\n",
    "\n",
    "Rule 3: When LSTA <= 9.73%  AND __RM <= 7.74__  AND DIS > 1.485 AND __RM > 6.64__ â€”> Predicted medv= $31 360\n",
    "\n",
    "We can simplify this rule a little bit as follows:\n",
    "\n",
    "__When LSTA <= 9.73%  AND  6.64 <RM<= 7.74  AND  DIS > 1.485 then: Predicted medv= $31 360__\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Rule 4: When LSTA <= 9.73% AND __RM <= 7.74__ AND DIS > 1.485 AND __RM <= 6.64__ then: predicted medv= $ 23 746\n",
    "\n",
    "We can simplify this rule a little bit as follows:\n",
    " \n",
    "__When LSTA <= 9.73% AND RM <= 6.64 AND DIS > 1.485 then: predicted medv= $ 23 746__\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Some insights from these rules (more insights are possible):\n",
    "\n",
    "In neighborhoods with low LSTAT, the average number of rooms in the houses (RM) takes an important role in determining the median value of the houses. \n",
    "\n",
    "\n",
    "When LSTAT is low and RM is above 7.44, the median house value in the neighborhood is quite high ($ 44 318)\n",
    "\n",
    "\n",
    "When LSTAT is low, even if RM is less than or equal to 7.44, there is still a situation where the median house value could be even higher than the previous case. That is when DIS (the average dist to five urban centers) is low (below 1.49). Under these three conditions, the the median house value in the neighborhood is very high ($ 50 000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a093601",
   "metadata": {},
   "source": [
    "### Post-pruning approach 2: selecting alpha via CV \n",
    "\n",
    "WORK IN PROGRESS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
