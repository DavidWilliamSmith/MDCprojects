{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "005026fd",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook illustrates the concepts of posterior probability and probability threshold. It shows how changing the probability threshold changes the performance metrics of a classifier.\n",
    "\n",
    "In this notebook, we will __re-aply classification trees to the Caravan and Defaults datasets__. \n",
    "\n",
    "We will apply the post-prunned strategy based on CCP as we did before, then, we will modify the probablity threshold of the post-prunned tree to observed the effect of this change. \n",
    "\n",
    "Why do we focus on the post-prunned tree only? Because we have repeatedly observed that post-prunning leads to better results than pre-prunning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b64020c",
   "metadata": {},
   "source": [
    "### Post-prunning applied to the caravan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b54add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0aa106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Caravan_df= pd.read_csv('C:\\\\Users\\\\jheredi2\\\\Documents\\\\PythonDataAnalytics\\\\1-Datasets\\\\Caravan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(Caravan_df['Purchase'].value_counts(normalize= True), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the first predictor from the Caravan data set\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split (Caravan_df.iloc[:,1:-1], Caravan_df['Purchase'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_unprunned= DecisionTreeClassifier(criterion='gini', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adae6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= tree_caravan_unprunned.cost_complexity_pruning_path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c781d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas= path['ccp_alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores=[]\n",
    "for i in alphas:\n",
    "    treeloop= DecisionTreeClassifier(ccp_alpha=i, random_state=1)\n",
    "    treeloop.fit(X_train, y_train)\n",
    "    y_test_predicted=treeloop.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_test_predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa861e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmax=accuracy_scores.index(max(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a04cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_postprunned= DecisionTreeClassifier(ccp_alpha= alphas[indexmax], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_postprunned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646a1fe",
   "metadata": {},
   "source": [
    "### Posterior probabilities for a classification tree and the probability threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad455fe3",
   "metadata": {},
   "source": [
    "Calling the method __predict_proba()__ on the tree object will return, for each test observation, the prob of No and the prob of Yes, given the values of the predictors for each observation. In other words, __predict_proba()__ returns the __posterior probabilities__.\n",
    "\n",
    "The method __predict_proba()__ returns a two dimensional array with Nt rows (the number of test observations) and two columns, each column with the posterior probablity for each class (= Col 1 wih the prob of No and Col 2 with the prob of Yes).\n",
    "\n",
    "See next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bde67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To know the order of the classes, you can apply unique()\n",
    "\n",
    "Caravan_df['Purchase'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1192353",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_caravan_postprunned.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc7f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following statement will retrieve the second probability (the probability of Yes) for each test observation\n",
    "\n",
    "tree_caravan_postprunned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343b4d2",
   "metadata": {},
   "source": [
    "A classification tree is implemented by default to minimize the overall error rate, therefore, it will predict Yes only when the posterior probability of Yes is > 0.5\n",
    "\n",
    "As we can see next, most observations are predicted No because the probablity of Yes <=0.5 for most observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce55c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of values taken by posterior probability for Y= 1\n",
    "\n",
    "pd.Series (tree_caravan_postprunned.predict_proba(X_test)[:,1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of predictions of Yes and No\n",
    "\n",
    "pd.Series(tree_caravan_postprunned.predict(X_test)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f88f94",
   "metadata": {},
   "source": [
    "The next code cell checks that the prediction is Yes only for the two observations for which prob of Yes > 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96dbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all ( (tree_caravan_postprunned.predict_proba(X_test)[:,1]>0.5) == (tree_caravan_postprunned.predict(X_test)=='Yes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65bedf",
   "metadata": {},
   "source": [
    "__Changing the probability threshold from 0.5 to 0.25__.\n",
    "\n",
    "This implies that the tree will classify an observation as 'Yes' when prob of Yes > 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d89b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with all the probabilities of Yes\n",
    "\n",
    "prob_yes= tree_caravan_postprunned.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20746f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop computes the prediction of Y (No or Yes) for each test observation\n",
    "# The predictions of Y are stored in an array called 'y_predicted_prob025' \n",
    "# The prediction uses a prob threshold of 0.25\n",
    "\n",
    "y_predicted_prob025=np.empty(y_test.size, dtype=object)\n",
    "\n",
    "for i in np.arange(0,y_predicted_prob025.size):\n",
    "    if prob_yes[i] > 0.25:\n",
    "        y_predicted_prob025[i]= 'Yes'\n",
    "    else:\n",
    "        y_predicted_prob025[i]= 'No'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f7bd7",
   "metadata": {},
   "source": [
    "The number of 'Yes' predicted by the Tree has increased after lowering the threshold to 0.25 (see next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_predicted_prob025).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67415434",
   "metadata": {},
   "source": [
    "Do we get better performance metrics with a threshold of 0.25 compared to 0.5? Let's get the confusion matrix and the results from the classification report\n",
    "\n",
    "Note: The results with 0.5 are in the first notebook about classification trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45532f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_predicted_prob025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdde186",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report (y_test, y_predicted_prob025))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac18cb",
   "metadata": {},
   "source": [
    "####  Are there other probability thresholds that can be used to make predictions?\n",
    "\n",
    "Why did I select 0.25 instead of 0.65 or 0.75?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ce789",
   "metadata": {},
   "source": [
    "#### Why am I focusing on the Yes class? Why do I emphasize getting a better accuracy (i.e., recall) for the Yes class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82c27b",
   "metadata": {},
   "source": [
    "#### Creating other probability thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of probability thresholds\n",
    "\n",
    "array_prob= np.arange(0.05, 0.51, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4440e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af82ac6",
   "metadata": {},
   "source": [
    "#### Selecting the best probability threshold based on the f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e21f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9946651",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f1_scores= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in array_prob:\n",
    "    dict_predictions[j]=np.empty(y_test.size, dtype=object)\n",
    "    for i in np.arange(0, dict_predictions[j].size):\n",
    "        if prob_yes[i] > j:\n",
    "            dict_predictions[j][i]= 'Yes'\n",
    "        else:\n",
    "            dict_predictions[j][i]= 'No'\n",
    "    dict_f1_scores[j]= np.round (f1_score(y_test, dict_predictions[j],pos_label='Yes'),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2a0122",
   "metadata": {},
   "source": [
    "What probability threshold results in the highest f1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dict_f1_scores, key= dict_f1_scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13202c07",
   "metadata": {},
   "source": [
    "What's the highest f1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dict_f1_scores.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6fd191",
   "metadata": {},
   "source": [
    "__JUST FOR ILLUSTRATION PURPOSES ...__\n",
    "\n",
    "#### Selecting the best probability threshold based on the accuracy for the Yes class (i.e., recall for the Yes class)\n",
    "\n",
    "GENERALLY, NOT A GOOD IDEA TO SELECT BASED ON RECALL ONLY !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_recall_scores= dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f25529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in array_prob:\n",
    "    dict_recall_scores[j]= np.round (recall_score(y_test, dict_predictions[j],pos_label='Yes'),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9b170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_recall_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e61f0",
   "metadata": {},
   "source": [
    "Since we got the best f1-score with threshold 0.1, let's use this threshold to make predictions and obtain the confusion matrix and classification report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop computes the prediction of Y (No or Yes) for each test observation\n",
    "# The predictions of Y are stored in an array called 'y_predicted_prob010' \n",
    "# The prediction uses a prob threshold of 0.1\n",
    "\n",
    "y_predicted_prob010=np.empty(y_test.size, dtype=object)\n",
    "\n",
    "for i in np.arange(0,y_predicted_prob010.size):\n",
    "    if prob_yes[i] > 0.10:\n",
    "        y_predicted_prob010[i]= 'Yes'\n",
    "    else:\n",
    "        y_predicted_prob010[i]= 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177641b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix (y_test, y_predicted_prob010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab519a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (classification_report (y_test, y_predicted_prob010))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc579c9e",
   "metadata": {},
   "source": [
    "### Post-prunning applied to the default dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326934bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_df= pd.read_csv('C:\\\\Users\\\\jheredi2\\\\Documents\\\\PythonDataAnalytics\\\\1-Datasets\\\\Default.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_df_dummies= pd.get_dummies(Default_df,columns=['student'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535bc1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_def, X_test_def, y_train_def, y_test_def= train_test_split (Default_df_dummies.iloc[:,1:], Default_df_dummies['default'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f14f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_default_unprunned= DecisionTreeClassifier(criterion='gini', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b2f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_def= tree_caravan_unprunned.cost_complexity_pruning_path(X_train_def, y_train_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe03d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_def= path_def['ccp_alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7049bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores=[]\n",
    "for i in alphas_def:\n",
    "    treeloop= DecisionTreeClassifier(ccp_alpha=i, random_state=1)\n",
    "    treeloop.fit(X_train_def, y_train_def)\n",
    "    y_test_predicted=treeloop.predict(X_test_def)\n",
    "    accuracy_scores.append(accuracy_score(y_test_def, y_test_predicted)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmax=accuracy_scores.index(max(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78094219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_default_postprunned= DecisionTreeClassifier(ccp_alpha= alphas_def[indexmax], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_default_postprunned.fit(X_train_def, y_train_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_postprunned_predicted_test= tree_default_postprunned.predict(X_test_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_def, default_postprunned_predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report (y_test_def, default_postprunned_predicted_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e548a3e",
   "metadata": {},
   "source": [
    "### TO DO INDEPENDENTLY FOR 10 MINUTES!\n",
    "\n",
    "#### Choose the value of the probability threshold that gives you the best f1-score\n",
    "\n",
    "#### Obtain the confusion matrix and the probability report using the chosen probability threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
