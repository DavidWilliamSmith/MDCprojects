{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df=pd.DataFrame(boston_data.data, columns= boston_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a067cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df['medv']= boston_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The next statement imports the method to apply Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# In case we need to build a regression tree, let's import these two classes:\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ced53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split (boston_df.iloc[:,:-1],boston_df['medv'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79186f51",
   "metadata": {},
   "source": [
    "## Bagging (i.e., Non-random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b12648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees to include in the forest. We are considering from 50 to 500 trees.\n",
    "\n",
    "number_of_trees=np.arange(50,501,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4a3c9",
   "metadata": {},
   "source": [
    "The difference between Bagging and RF is that for the former,max_features=n_features; whereas for the latter, max_features < n_features\n",
    "\n",
    "When applying Bagging, how to set max_features=n_features?\n",
    "\n",
    "From scikit-learn: If max_features is None or 1.0, then max_features=n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298f861",
   "metadata": {},
   "source": [
    "Let's use a loop to compute the __oob MSE__ for a forest trained with i tress (where i goes from 50 to 500)\n",
    "\n",
    "The expression \"bag_loop.oob_prediction_\" computes the prediction of Y for each oob observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fab26d",
   "metadata": {},
   "source": [
    "__Note__: The following loop is built under the assumption that each observation in the training data will be an out-of-the-bag observation at least once. It is more likely that this assumption is satisfied IF the number of trees is large enough. That's why we are starting with at least 50 trees in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_bagging_oob_scores=[]\n",
    "for i in number_of_trees:\n",
    "    bag_loop= RandomForestRegressor(n_estimators = i, oob_score= True, max_features=None, random_state=1)\n",
    "    bag_loop.fit(X_train, y_train)\n",
    "    mse_bagging_oob_scores.append(mean_squared_error(y_train, bag_loop.oob_prediction_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(mse_bagging_oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmin_bagging= mse_bagging_oob_scores.index(min(mse_bagging_oob_scores))\n",
    "indexmin_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251399ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of trees in this non-random forest that led to the lowest oob MSE was:\n",
    "\n",
    "number_of_trees[indexmin_bagging]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f703533",
   "metadata": {},
   "source": [
    "#### Estimate the test MSE of the bagging (non-random) forest obtained with number of trees equals to 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_forest= RandomForestRegressor(n_estimators= 180, max_features=None, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be218fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68874562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error( y_test, bagging_forest.predict (X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3164c",
   "metadata": {},
   "source": [
    "A test MSE of 8.51 is the best test error we have got so far with the Boston dataset !!! (considering all the techniques we have applied to the Boston dataset: regression trees, linear regression, non-linear regression)\n",
    "\n",
    "With multiple linear regression, we got a root MSE in the order of 5 to 6. The root MSE for this non-random forest is less than 3!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a5b87",
   "metadata": {},
   "source": [
    "### GO BACK TO THE SLIDES !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bf9b2",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Approach 1 (the theory-based approach): Do not prune the trees and use the OOB error to decide the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00a187",
   "metadata": {},
   "source": [
    "Let's use a loop to compute the oob MSE for a forest trained with i tress (where i goes from 50 to 500)\n",
    "\n",
    "In Random Forest, in contrast with Bagging, we could also vary the parameter max_feature and try to select its \"best\" value. However, __we will not do that now (we will do it later)__. We will use max_features= sqrt (p) (the sqrt(p) is a usually recommended value for the max_feature parameter)\n",
    "\n",
    "The expression \"rf_loop.oob_prediction_\" computes the prediction of Y for each oob observation.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b06f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rf_oob_scores=[]\n",
    "for i in number_of_trees:\n",
    "    rf_loop= RandomForestRegressor(n_estimators = i, oob_score= True, max_features=\"sqrt\", random_state=1)\n",
    "    rf_loop.fit(X_train, y_train)\n",
    "    mse_rf_oob_scores.append(mean_squared_error(y_train, rf_loop.oob_prediction_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0617b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(mse_rf_oob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmin_rf= mse_rf_oob_scores.index(min(mse_rf_oob_scores))\n",
    "indexmin_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4cd26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The number of trees in this random forest that led to the lowest oob MSE was:\n",
    "\n",
    "number_of_trees[indexmin_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15858c",
   "metadata": {},
   "source": [
    "For homework 5, you could stop in the previous step and conclude that the number of trees is 320. __Doing the following re-tuning is optional.__\n",
    "\n",
    "__Re-tunning__: Run the loop again using a different random state value to get different trees. This time, only consider a number of trees closer to 320. My goal here is to be more sure that the best number of trees is actually around 320 instead of a larger number closer to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d11fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trees2=np.arange(300,501,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change randomness by setting random state=2\n",
    "\n",
    "mse_rf_oob_scores2=[]\n",
    "for i in number_of_trees2:\n",
    "    rf_loop= RandomForestRegressor(n_estimators = i, oob_score= True, max_features=\"sqrt\", random_state=2)\n",
    "    rf_loop.fit(X_train, y_train)\n",
    "    mse_rf_oob_scores2.append(mean_squared_error(y_train, rf_loop.oob_prediction_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(mse_rf_oob_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97871cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexmin_rf= mse_rf_oob_scores2.index(min(mse_rf_oob_scores2))\n",
    "indexmin_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c8d21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_trees2[indexmin_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df882505",
   "metadata": {},
   "source": [
    "#### Estimate the test MSE of the random forest obtained with number of trees equals to... 320 (if you did not do the optional re-tuning) or 340 (if you did the retuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestRegressor(n_estimators= 340, max_features=\"sqrt\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a783b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error( y_test,rf.predict (X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558d035",
   "metadata": {},
   "source": [
    "This is a good (low) test MSE, but it is a bit worse (greater) than the one using Bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0b16a",
   "metadata": {},
   "source": [
    "__Overall, what features are important in the trees part of the forest?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09063a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are calling the attribute \"feature_importances_\" on the random forest object\n",
    "\n",
    "df_feature_imp=pd.Series(data=rf.feature_importances_, index=boston_df.iloc[:,:-1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09958782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_imp.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea69eb9",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Approach 1 (version 2) (the theory-based approach): Do not prune the trees and use the OOB error to decide the best parameters. \n",
    "\n",
    "### This time, let's change both the max_features and the number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2823cfcd",
   "metadata": {},
   "source": [
    "Since the sqrt(p) is a good value to use for max_features, I want to know what's the sqrt(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[1])\n",
    "print(np.sqrt(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c979b",
   "metadata": {},
   "source": [
    "Let's change the number of features from 3 to 7 (7 ~ p/2, since p=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09971161",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features=np.arange(3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2df8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trees2=np.arange(300,501,10)\n",
    "\n",
    "# Starting at 300 to lower the burden of the upcoming loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores_rf_oob_matrix= np.empty((number_of_features.size, number_of_trees2.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9365245",
   "metadata": {},
   "source": [
    "mse_scores_rf_oob_matrix is an empty matrix with as many rows as number of features being tested\n",
    "and as many columns as number of tree being tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores_rf_oob_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0\n",
    "for i in number_of_features:\n",
    "    c=0\n",
    "    for j in number_of_trees2:\n",
    "        rf_loop= RandomForestRegressor(n_estimators = j, oob_score= True, max_features=i, random_state=1)\n",
    "        rf_loop.fit(X_train, y_train)\n",
    "        mse_scores_rf_oob_matrix[r,c]= mean_squared_error(y_train, rf_loop.oob_prediction_)\n",
    "        c=c+1\n",
    "    r= r+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b888df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores_rf_oob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mse_scores_rf_oob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c638aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mse_scores_rf_oob_matrix == np.min(mse_scores_rf_oob_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4522df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mse_scores_rf_oob_matrix == np.min(mse_scores_rf_oob_matrix))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features for which the min MSE happens:\n",
    "\n",
    "number_of_features[np.where(mse_scores_rf_oob_matrix == np.min(mse_scores_rf_oob_matrix))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01841dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees for which the min MSE happens:\n",
    "\n",
    "number_of_trees2[np.where(mse_scores_rf_oob_matrix == np.min(mse_scores_rf_oob_matrix))[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845c23b",
   "metadata": {},
   "source": [
    "#### Estimate the test MSE of the random forest obtained with number of trees equals to 430 and 6 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2= RandomForestRegressor(n_estimators= 430, max_features=6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadf2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error( y_test,rf2.predict (X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ef2f5",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Approach 2 (the practice-based approach): Do not prune the trees (similar to approach 1). \n",
    "\n",
    "### The difference with approach 1 is that instead of using the OOB error to decide the best parameters, we can use CV to decide the best parameter.\n",
    "\n",
    "##### We can apply CV by using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6793ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb0b53",
   "metadata": {},
   "source": [
    "Since the sqrt(p) is a good value to use for max_features, I want to know what's the sqrt(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[1])\n",
    "print(np.sqrt(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7f931",
   "metadata": {},
   "source": [
    "Let's change the number of features from 3 to 7 (7 ~ p/2, since p=13)\n",
    "\n",
    "Let's change the number of trees from 300 to 500\n",
    "\n",
    "Note: I chose to go from 300 to 500 rather than from 50 to 500 to make the fit process run faster\n",
    "\n",
    "The search is going to take btw 3 to 4 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {    \n",
    "    'n_estimators': np.arange(300,501,10),   \n",
    "     'max_features': np.arange(3,8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f651826",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fcc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters: ', gridSearch_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb3dea",
   "metadata": {},
   "source": [
    "#### Estimate the test MSE of the random forest obtained with number of trees equals to ?? and 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf3= RandomForestRegressor(n_estimators= , max_features=7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf80a374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mean_squared_error( y_test,rf3.predict (X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
