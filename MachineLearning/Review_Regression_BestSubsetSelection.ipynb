{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bbe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aee9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data=datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df=pd.DataFrame(boston_data.data, columns= boston_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec43fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df['medv']= boston_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffa98a",
   "metadata": {},
   "source": [
    "### The Best Subset Selection method\n",
    "\n",
    "We studied this method in the \"Statistics with R class\" as a way of choosing a good multiple regression equation. \n",
    "\n",
    "Remember that choosing between equations with different number of predictor variables should be done with care. The best subset selection method allows us to navigate this problem and get a good solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0930a",
   "metadata": {},
   "source": [
    "In R, we used the \"regsubsets()\" method from the \"leaps\" library to apply the best subset selection method.\n",
    "\n",
    "The \"regsubsets()\" method returns a list with the best equation of each size (the best equation with one predictor, the best equation with two predictors,...., and the best equation  with p predictors).\n",
    "\n",
    "Then, the \"regsubsets()\" method allows us to compare these equations and choose the single best one. This comparison can be done using adjusted R squared, Cp, or BIC (Bayesian Information Criterion). In our case, we used adjusted R squared to do these comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca61769",
   "metadata": {},
   "source": [
    "### The Best Subset Selection method in Python\n",
    "\n",
    "In Python, we can run a best subset selection analysis by using the methods from the ABESS library.\n",
    "\n",
    "ABESS: Adaptative Best Subset Selection\n",
    "\n",
    "ABESS uses a rather advanced algorithm to run best subset selection; thus, it is beyond the scope of this class to go over the details of this algorithm. We will focus on learning __how to apply ABESS in Python__ and __how to interpret its results.__\n",
    "\n",
    "ABESS uses BIC (Bayesian Information Criterion) to choose the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abess import abessLm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51098c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from abess import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abess = abessLm(support_size = range(14))  # range(14) equivalent to np.arange(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c181ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_abess = LinearRegression(support_size = range(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d26892",
   "metadata": {},
   "source": [
    "The argument __support size__ is similar to the argument __mvmax__ in R. It represents the maximum model size that you want to consider. In this case, we want to consider all possible model sizes, from 1 ( a model with one predictor) all the way to 13 predictors (a model with all predictors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71449cd5",
   "metadata": {},
   "source": [
    "Now we need to call the method __fit()__ on the object _model_abess_ that we created in the previous cell.\n",
    "\n",
    "The fit() method takes arrays as arguments. Thus, we need to convert the boston data from a Pandas data frame into a Numpy array.\n",
    "\n",
    "The method fit () takes two arguments: X (the array with the predictor values) and Y (the array with the values of Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc02384",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array with the predictors\n",
    "# Convert the boston_df, excluding the last column which is 'medv', into a Numpy array\n",
    "\n",
    "Xs_array= np.array(boston_df.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array with Y\n",
    "\n",
    "y_array= np.array(boston_df['medv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97271cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abess.fit(Xs_array, y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98366788",
   "metadata": {},
   "source": [
    "The result of the ABESS algorithm is an array of coefficients where __only the coefficients for the predictors that ABESS has chosen has a value different from zero__. The predictors that ABESS excludes from the chosen equation have a coefficient of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbbc05",
   "metadata": {},
   "source": [
    "We can call the property \"coef_\" on the object _model_abess_ that we created before to see what coefficients are different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb110def",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abess.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e144d",
   "metadata": {},
   "source": [
    "If we want to select only the coefficients different from zero, we can take the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abess.coef_!=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f078afd",
   "metadata": {},
   "source": [
    "We can store this Boolean array in a variable to use it later to index the array of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fd695",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indexes = model_abess.coef_!=0\n",
    "non_zero_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337431a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the coefficients different from zero\n",
    "\n",
    "model_abess.coef_[non_zero_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4b870",
   "metadata": {},
   "source": [
    "What are the predictors which coefficients are different from zero? In other words, what are the predictors chosen by ABESS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list with the column names for the predictors\n",
    "\n",
    "boston_df.iloc[:,:-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get the predictors which coefficients are different from zero\n",
    "\n",
    "boston_df.iloc[:,:-1].columns[non_zero_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aedf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_predictors= boston_df.iloc[:,:-1].columns[non_zero_indexes]\n",
    "selected_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c892e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('According to Abess, the predictors to be included in the model are :', selected_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927604df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('According to Abess, the predictors to be included in the model are :', list(selected_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f43798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Coefficients':model_abess.coef_[non_zero_indexes]}, index=list(selected_predictors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a7b3a",
   "metadata": {},
   "source": [
    "#### Last comments about ABESS\n",
    "\n",
    "- When you apply the best subset selection method in R to return the coefficients of the model with seven predictors you get the same coefficients that we just got! This was expected, but it is good to check that results are consistent across tools.\n",
    "\n",
    "\n",
    "- One problem with the previous list of coefficients is that it does not include the intercept. One solution could be to run linear regression using Statsmodels as we did in a previous session. \n",
    "\n",
    "You would run the regression in Statsmodels with these seven predictors. The output of Statsmodels will return the intercept and these seven coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77044ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ccbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols('medv~'+ '+'.join(selected_predictors), data=boston_df).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols('medv~'+ '+'.join(selected_predictors), data=boston_df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582368a6",
   "metadata": {},
   "source": [
    "### More on the best subset selection method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e80ad",
   "metadata": {},
   "source": [
    "Now, let's try to code some of the steps involved in the best subset selection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5a971",
   "metadata": {},
   "source": [
    "We will only code, __in a very intuitive and raw way__, some of the steps needed to conduct the first task required by the method: select the best model for each size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a237d",
   "metadata": {},
   "source": [
    "One of the first things we can do is to write a function that estimates a regression model and its corresponding R squared given:\n",
    "\n",
    "a) An array of Y values\n",
    "\n",
    "b) The two-dim array which columns contain the values for all the predictors\n",
    "\n",
    "c) A list of the predictors that the user wants to include in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I chose to use 'statsmodels.api' instead of 'statsmodels.formula.api' because the former is simpler when it comes\n",
    "# to write more generic code (i.e., code to include in a function)\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reg_model_rsq (y,Xs, feature_set):\n",
    "    \n",
    "    \"\"\"y and Xs are array-like objects.\n",
    "    They could be arrays or data frames.\n",
    "    Xs is the matrix with all the predictors.\n",
    "    y is the array/Series with the dependent variable values.\n",
    "    feature_set must be a list with the names of the predictors to incude in the equation\n",
    "    \"\"\"\n",
    "    X = sm.add_constant(Xs[feature_set])\n",
    "    reg_model= sm.OLS(y,X).fit()\n",
    "    return(reg_model.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f39225",
   "metadata": {},
   "source": [
    "__Note__: The following commands and the loops afterwards should all be included in a function that can be more generic and reusable. However, let's keep things simpler by hard-coding some the logic involved in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_list= list(boston_df.iloc[:,:-1].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8aff33",
   "metadata": {},
   "source": [
    "Task # 1 in best subset selection is to get the best equation of each size. That is, the best equation with 1 predictor, the best equation with two predictors,..., the best equation with p predictors.\n",
    "\n",
    "Task # 2: Select the single best among the previous equations. We based this comparison on Adj R squared, BIC, Cp, test MSE (via CV), or other suitable metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863a481",
   "metadata": {},
   "source": [
    "Task # 1:\n",
    "\n",
    "Step 1: Select the best equation with one predictor (the one with the highest R squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52803a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsq_list=[]\n",
    "for i in predictors_list:\n",
    "    # In the next line, there is a call to the function 'my_reg_model_rsq' that we created earlier\n",
    "    rsq_list.append(my_reg_model_rsq(boston_df['medv'],boston_df.iloc[:,:-1],i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25841861",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best equation with one predictor is the one that includes :', np.array(predictors_list)[rsq_list==max(rsq_list)])\n",
    "print('The Rsq of this equation is: ', np.round(max(rsq_list),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f9f00",
   "metadata": {},
   "source": [
    "Task # 1:\n",
    "\n",
    "Step 2: Select the best equation with two predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043fc64",
   "metadata": {},
   "source": [
    "Let's repeat the previous logic to get the best equation with two predictors.\n",
    "\n",
    "We need to figure out how to get __a list with all the combinations of two predictors__ that can formed from the 13 predictors available in the Boston dataset.\n",
    "\n",
    "The method combinations() from the itertools library can be used with this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_two_predictors= list(itertools.combinations(predictors_list, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_two_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64375200",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsq_list1=[]\n",
    "for i in list_two_predictors:\n",
    "    rsq_list1.append(my_reg_model_selection(boston_df['medv'],boston_df.iloc[:,:-1],list(i))) \n",
    "    # list(i) instead of i because i is a tuple and my_reg_model_selection takes a list as the 3rd argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best equation with two predictors is the one that includes :', np.array(list_two_predictors)[rsq_list1==max(rsq_list1)])\n",
    "print('The Rsq of this equation is: ', np.round(max(rsq_list1),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6e944",
   "metadata": {},
   "source": [
    "### Work independently on the following tasks\n",
    "\n",
    "### You will have five minutes to work on this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df724927",
   "metadata": {},
   "source": [
    "Task 1: Repeat the previous logic and get the best equation with three predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844ab80",
   "metadata": {},
   "source": [
    "Task 2: Apply ABESS to get the best equation with three predictors and check that you get the same result obtained in task 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
